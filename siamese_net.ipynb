{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(b_convert_to_grayscale=True, batch_size=100, crop_factor=1.0, dataset='lfw', distance_fn='l2', filename='C:\\\\Users\\\\Prasad\\\\AppData\\\\Roaming\\\\jupyter\\\\runtime\\\\kernel-58306c74-1289-47a3-a8d3-68de63b21861.json', hyperparameter_margin=2.0, hyperparameter_threshold=5.0, learning_rate=0.0001, model_type='hani', n_epochs=5, n_out=40, nonlinearity='rectify', normalization='-1:1', num_files=2, path_to_data=None, resolution=64, spatial=False)\n",
      "Dataset: lfw\n",
      "Spatial: 0\n",
      "Batch Size: 100\n",
      "Num Features: 40\n",
      "Model Type: hani\n",
      "Num Epochs: 5\n",
      "Num Files: 2\n",
      "Learning Rate: 0.000100\n",
      "Normalization: -1:1\n",
      "Crop Factor: 1.000000\n",
      "Resolution: 64\n",
      "Hyperparameter Margin: 2.000000\n",
      "Hyperparameter Threshold: 5.000000\n",
      "Non-Linearity: rectify\n",
      "Grayscale: 1\n",
      "Distance Function: l2\n",
      "\n",
      "Writing results to: C:\\Users\\Prasad\\AppData\\Roaming\\jupyter\\runtime\\kernel-58306c74-1289-47a3-a8d3-68de63b21861.json\n",
      "\n",
      "Loading dataset...\n",
      "Preprocessing dataset\n",
      "Cannot find dataset at: C:\\Users\\Prasad\\Handy-Gestures\\lfw\n",
      "Downloading dataset from http://vis-www.cs.umass.edu/lfw/lfw.tgz...\n",
      "Extracting dataset...\n",
      "Loading data in ./lfw\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: './lfw'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-8a0d8ece6c65>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1623\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1624\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1625\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-8a0d8ece6c65>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(argv)\u001b[0m\n\u001b[0;32m   1618\u001b[0m                                  args.hyperparameter_threshold),\n\u001b[0;32m   1619\u001b[0m                              \u001b[0mpath_to_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath_to_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1620\u001b[1;33m                              filename=args.filename)\n\u001b[0m\u001b[0;32m   1621\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1622\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-8a0d8ece6c65>\u001b[0m in \u001b[0;36mrun_siamese_net_training\u001b[1;34m(dataset, spatial, batch_size, learning_rate, model_type, n_epochs, n_out, num_files, normalization, resolution, crop_factor, hyperparameter_margin, hyperparameter_threshold, nonlinearity, distance_fn, b_convert_to_grayscale, filename, path_to_data, b_load_idxs_only)\u001b[0m\n\u001b[0;32m   1268\u001b[0m         \u001b[0mpath_to_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_to_data\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1269\u001b[0m         \u001b[0mb_load_idxs_only\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb_load_idxs_only\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1270\u001b[1;33m         b_convert_to_grayscale=b_convert_to_grayscale)\n\u001b[0m\u001b[0;32m   1271\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1272\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Initializing Siamese Network...'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-11-8a0d8ece6c65>\u001b[0m in \u001b[0;36mload_pairs\u001b[1;34m(dataset, normalization, split, resolution, crop_style, crop_factor, n_files_per_person, path_to_data, b_load_idxs_only, b_convert_to_grayscale)\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[0mb_convert_to_grayscale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mb_convert_to_grayscale\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m         )\n\u001b[1;32m--> 224\u001b[1;33m         \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mds\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_parsed_dataset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpath_to_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_to_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    225\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mdict\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'target'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'images'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[0mds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Prasad\\Handy-Gestures\\datasets.ipynb\u001b[0m in \u001b[0;36mget_parsed_dataset\u001b[1;34m(self, dataset, path_to_data)\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Prasad\\Handy-Gestures\\datasets.ipynb\u001b[0m in \u001b[0;36m_get_lfw_dataset\u001b[1;34m(self, path_to_data)\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\Prasad\\Handy-Gestures\\datasets.ipynb\u001b[0m in \u001b[0;36m_get_one_level_deep\u001b[1;34m(self, path_to_data, token1, token2)\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: './lfw'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import os\n",
    "import import_ipynb\n",
    "\n",
    "# base_compiledir = os.path.expandvars(\"$HOME/.theano/slot-%d\" % (os.getpid()))\n",
    "# os.environ['THEANO_FLAGS'] = \"base_compiledir=%s\" % base_compiledir\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import theano\n",
    "import theano.tensor as T\n",
    "import time\n",
    "import lasagne\n",
    "\n",
    "# For training the final output network\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Custom code for parsing datasets and normalizing images\n",
    "from datasets import Datasets\n",
    "from normalization import LCN, ZCA\n",
    "\n",
    "# plt.style.use('ggplot')\n",
    "theano.config.floatX = 'float32'\n",
    "\n",
    "\n",
    "def montage(x):\n",
    "    if x.shape[1] == 1 or x.shape[1] == 3:\n",
    "        num_img = x.shape[0]\n",
    "        num_img_per_dim = np.ceil(np.sqrt(num_img)).astype(int)\n",
    "        montage_img = np.zeros((\n",
    "            num_img_per_dim * x.shape[3],\n",
    "            num_img_per_dim * x.shape[2], x.shape[1]))\n",
    "    else:\n",
    "        num_img_per_dim = np.ceil(np.sqrt(x.shape[1])).astype(int)\n",
    "        montage_img = np.zeros((\n",
    "            num_img_per_dim * x.shape[3],\n",
    "            num_img_per_dim * x.shape[2]))\n",
    "        num_img = x.shape[1]\n",
    "\n",
    "    for img_i in range(num_img_per_dim):\n",
    "        for img_j in range(num_img_per_dim):\n",
    "            if img_i * num_img_per_dim + img_j < num_img:\n",
    "                if x.shape[0] == 1:\n",
    "                    montage_img[\n",
    "                        img_i * x.shape[3]: (img_i + 1) * x.shape[2],\n",
    "                        img_j * x.shape[3]: (img_j + 1) * x.shape[2]\n",
    "                    ] = np.squeeze(np.squeeze(\n",
    "                        x[0, img_i * num_img_per_dim + img_j, ...]\n",
    "                    ) / (np.max(x[0, img_i * num_img_per_dim + img_j, ...]\n",
    "                                ) + 1e-15))\n",
    "                else:\n",
    "                    montage_img[\n",
    "                        img_i * x.shape[3]: (img_i + 1) * x.shape[2],\n",
    "                        img_j * x.shape[3]: (img_j + 1) * x.shape[2],\n",
    "                        :\n",
    "                    ] = np.swapaxes(np.squeeze(\n",
    "                        x[img_i * num_img_per_dim + img_j, ...]\n",
    "                    ) / (np.max(x[img_i * num_img_per_dim + img_j, ...]\n",
    "                                ) + 1e-15), 0, 2)\n",
    "    return montage_img\n",
    "\n",
    "\n",
    "def get_image_manifold(images, features, res=64, n_neighbors=5):\n",
    "    '''Creates a montage of the images based on a TSNE\n",
    "    manifold of the associated image features.\n",
    "    '''\n",
    "\n",
    "    from sklearn import manifold\n",
    "    mapper = manifold.SpectralEmbedding()\n",
    "    transform = mapper.fit_transform(features)\n",
    "    nx = int(np.ceil(np.sqrt(len(transform))))\n",
    "    ny = int(np.ceil(np.sqrt(len(transform))))\n",
    "    montage_img = np.zeros((res * nx, res * ny, 3))\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    nn = NearestNeighbors()\n",
    "    nn.fit(transform)\n",
    "    min_x = np.mean(transform[:, 0]) - np.std(transform[:, 0]) * 3.0\n",
    "    max_x = np.mean(transform[:, 0]) + np.std(transform[:, 0]) * 3.0\n",
    "    min_y = np.mean(transform[:, 1]) - np.std(transform[:, 1]) * 3.0\n",
    "    max_y = np.mean(transform[:, 1]) + np.std(transform[:, 1]) * 3.0\n",
    "\n",
    "    for n_i in range(nx):\n",
    "        for n_j in range(ny):\n",
    "            x = min_x + (max_x - min_x) / nx * n_i\n",
    "            y = min_y + (max_y - min_y) / ny * n_j\n",
    "            idx = nn.kneighbors([x, y], n_neighbors=n_neighbors)[1][0][:]\n",
    "            for neighbor_i in idx:\n",
    "                montage_img[\n",
    "                    n_i * res: (n_i + 1) * res, n_j * res: (n_j + 1) * res, :] += images[neighbor_i]\n",
    "            montage_img[\n",
    "                n_i * res: (n_i + 1) * res, n_j * res: (n_j + 1) * res, :] /= float(len(idx))\n",
    "    montage_img = montage_img / np.max(montage_img)\n",
    "    return montage_img\n",
    "\n",
    "\n",
    "def make_image_pairs(X, y, unique_labels):\n",
    "    from itertools import combinations\n",
    "\n",
    "    X_pairs_matched = list()\n",
    "    y_pairs_matched = list()\n",
    "\n",
    "    # Iterate over all actual pairs\n",
    "    # 32 choose 2 = 496 people pairs. 496 * (10 images choose 2) = 496 * 45 =\n",
    "    # 1440\n",
    "    for person in unique_labels:\n",
    "        # Find images of those people\n",
    "        im_idx = np.where(person == y)[0]\n",
    "        for el in combinations(im_idx, 2):\n",
    "            X_pairs_matched.append(\n",
    "                np.concatenate((X[el[0], ...], X[el[1], ...]),\n",
    "                               axis=0)[np.newaxis, ...])\n",
    "            y_pairs_matched.append(1)\n",
    "\n",
    "    X_pairs_unmatched = list()\n",
    "    y_pairs_unmatched = list()\n",
    "\n",
    "    # Iterate over all imposter pairs of people\n",
    "    # (32 choose 2 = 496 people pairs. 496 * 10 * 10 image pairs =\n",
    "    # 49600 imposter pairs)\n",
    "    # (157 * 0.4 = 63), 63 choose 2 = 1953, 1953 * 100 = 195300\n",
    "    for pair in combinations(unique_labels, 2):\n",
    "        # Find images of those people\n",
    "        im1_idx = np.where(pair[0] == y)[0]\n",
    "        im2_idx = np.where(pair[1] == y)[0]\n",
    "        for im1_idx_it in im1_idx:\n",
    "            for im2_idx_it in im2_idx:\n",
    "                X_pairs_unmatched.append(np.concatenate(\n",
    "                    (X[im1_idx_it, ...], X[im2_idx_it, ...]),\n",
    "                    axis=0)[np.newaxis, ...])\n",
    "                y_pairs_unmatched.append(0)\n",
    "\n",
    "    return (np.concatenate(X_pairs_matched),\n",
    "            np.array(y_pairs_matched),\n",
    "            np.concatenate(X_pairs_unmatched),\n",
    "            np.array(y_pairs_unmatched))\n",
    "\n",
    "\n",
    "def make_image_pair_idxs(y, unique_labels):\n",
    "    from itertools import combinations\n",
    "\n",
    "    X_pairs_matched = list()\n",
    "    y_pairs_matched = list()\n",
    "\n",
    "    # Iterate over all actual pairs\n",
    "    # 32 choose 2 = 496 people pairs. 496 * (10 images choose 2) = 496 * 45 =\n",
    "    # 1440\n",
    "    for person in unique_labels:\n",
    "        # Find images of those people\n",
    "        im_idx = np.where(person == y)[0]\n",
    "        for el in combinations(im_idx, 2):\n",
    "            X_pairs_matched.append(np.array([el[0], el[1]])[np.newaxis, ...])\n",
    "            y_pairs_matched.append(1)\n",
    "\n",
    "    X_pairs_unmatched = list()\n",
    "    y_pairs_unmatched = list()\n",
    "\n",
    "    # Iterate over all imposter pairs of people\n",
    "    # (32 choose 2 = 496 people pairs. 496 * 10 * 10 image pairs = 49600 imposter pairs)\n",
    "    # (157 * 0.4 = 63), 63 choose 2 = 1953, 1953 * 100 = 195300\n",
    "    for pair_i, pair in enumerate(combinations(unique_labels, 2)):\n",
    "        # Find images of those people\n",
    "        im1_idx = np.where(pair[0] == y)[0]\n",
    "        im2_idx = np.where(pair[1] == y)[0]\n",
    "        for im1_idx_it in im1_idx:\n",
    "            for im2_idx_it in im2_idx:\n",
    "                X_pairs_unmatched.append(\n",
    "                    np.array([im1_idx_it, im2_idx_it])[np.newaxis, ...])\n",
    "                y_pairs_unmatched.append(0)\n",
    "\n",
    "    return (np.concatenate(X_pairs_matched),\n",
    "            np.array(y_pairs_matched),\n",
    "            np.concatenate(X_pairs_unmatched),\n",
    "            np.array(y_pairs_unmatched))\n",
    "\n",
    "\n",
    "def draw_image_pair(X, y, idx=None):\n",
    "    if idx is None:\n",
    "        idx = np.random.randint(len(X) - 2)\n",
    "    if X.shape[1] == 1:\n",
    "        idx = idx + (idx % 2)\n",
    "    fig, [ax1, ax2] = plt.subplots(1, 2, figsize=(10, 8))\n",
    "    if X.shape[1] == 2:\n",
    "        ax1.imshow(np.squeeze(X[idx, 0, ...]), cmap='gray')\n",
    "        ax2.imshow(np.squeeze(X[idx, 1, ...]), cmap='gray')\n",
    "    else:\n",
    "        ax1.imshow(np.squeeze(X[idx, ...]), cmap='gray')\n",
    "        ax2.imshow(np.squeeze(X[idx + 1, ...]), cmap='gray')\n",
    "    ax1.grid(False)\n",
    "    ax2.grid(False)\n",
    "    if y[idx] == 0:\n",
    "        fig.suptitle('Unmatched: %d' % idx, fontsize=30)\n",
    "    else:\n",
    "        fig.suptitle('Matched: %d' % idx, fontsize=30)\n",
    "\n",
    "\n",
    "def load_pairs(\n",
    "        dataset='lfw',\n",
    "        normalization='LCN',\n",
    "        split=(0.8, 0.1, 0.1),\n",
    "        resolution=(128, 128),\n",
    "        crop_style='none',\n",
    "        crop_factor=1.2,\n",
    "        n_files_per_person=5,\n",
    "        path_to_data=None,\n",
    "        b_load_idxs_only=True,\n",
    "        b_convert_to_grayscale=True):\n",
    "    ds = None\n",
    "    if dataset == 'olivetti':\n",
    "        from sklearn.datasets import fetch_olivetti_faces\n",
    "        ds = fetch_olivetti_faces()\n",
    "        # TODO: Apply processing options to olivetti\n",
    "    elif dataset == 'lfw':\n",
    "        ds = Datasets(\n",
    "            crop_style=crop_style,\n",
    "            crop_factor=crop_factor,\n",
    "            resolution=resolution,\n",
    "            n_files_per_person=n_files_per_person,\n",
    "            n_min_files_per_person=(n_files_per_person / 2),\n",
    "            b_convert_to_grayscale=b_convert_to_grayscale\n",
    "        )\n",
    "        ds = ds.get_parsed_dataset(dataset=dataset, path_to_data=path_to_data)\n",
    "    elif dataset.__class__ is dict and 'target' in dataset.keys() and 'images' in dataset.keys():\n",
    "        ds = dataset\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            'Dataset should be either olivetti, lfw, or a dict defining images and target from get_parsed_dataset')\n",
    "\n",
    "    # Split up the dataset into unique targets for train/test,\n",
    "    # making sure not to repeat any subjects between train/test\n",
    "    # Should get 32 subjects train, 8 test, with a 0.8 split\n",
    "\n",
    "    y = ds['target']\n",
    "\n",
    "    total = len(np.unique(y))\n",
    "\n",
    "    train_split = int(total * split[0])\n",
    "    valid_split = train_split + int(total * split[1])\n",
    "    test_split = total - int(total * split[2])\n",
    "\n",
    "    unique_train_labels = np.unique(y)[:train_split]\n",
    "    unique_valid_labels = np.unique(y)[train_split:valid_split]\n",
    "    unique_test_labels = np.unique(y)[-test_split:]\n",
    "\n",
    "    # X = (400, 1, 64, 64);  y = (400,), 40 subjects w/ 10 examples each of 64\n",
    "    # x 64 pixels\n",
    "    if b_convert_to_grayscale:\n",
    "        X = np.concatenate([img[np.newaxis, np.newaxis, ...]\n",
    "                            for img in ds['images']], axis=0)\n",
    "    else:\n",
    "        X = np.concatenate([img[np.newaxis, ...]\n",
    "                            for img in ds['images']], axis=0)\n",
    "    print(X.shape)\n",
    "\n",
    "    if normalization == 'LCN':\n",
    "        lcn = LCN(sigma=round(0.0625 * X.shape[2]), subtractive=False)\n",
    "        lcn.fit(X[:len(y) * split[0], ...])\n",
    "        X = lcn.transform(X)\n",
    "    elif normalization == 'LCN-':\n",
    "        lcn = LCN(sigma=round(0.0625 * X.shape[2]), subtractive=True)\n",
    "        lcn.fit(X[:len(y) * split[0], ...])\n",
    "        X = lcn.transform(X)\n",
    "    elif normalization == 'ZCA':\n",
    "        zca = ZCA(bias=0.1)\n",
    "        zca.fit(X[:len(y) * split[0], ...])\n",
    "        X = zca.transform(X)\n",
    "    elif normalization == '-1:1':\n",
    "        for idx in range(len(X)):\n",
    "            X[idx, ...] = (X[idx, ...] - np.min(X[idx, ...])) / \\\n",
    "                (np.max(X[idx, ...]) - np.min(X[idx, ...])) * 2.0 - 1.0\n",
    "\n",
    "    if b_load_idxs_only:\n",
    "        # Make pairs of actual and imposter faces, returning the indexes to\n",
    "        # create them\n",
    "        print('train')\n",
    "        X_train_matched, y_train_matched, X_train_unmatched, y_train_unmatched = make_image_pair_idxs(\n",
    "            y, unique_train_labels)\n",
    "        print('valid')\n",
    "        X_valid_matched, y_valid_matched, X_valid_unmatched, y_valid_unmatched = make_image_pair_idxs(\n",
    "            y, unique_valid_labels)\n",
    "        print('test')\n",
    "        X_test_matched, y_test_matched, X_test_unmatched, y_test_unmatched = make_image_pair_idxs(\n",
    "            y, unique_test_labels)\n",
    "\n",
    "        return {\n",
    "            'X': lasagne.utils.floatX(X),\n",
    "            'y': y.astype(np.int32),\n",
    "            'X_train_matched_idxs': X_train_matched.astype(np.int32),\n",
    "            'y_train_matched_idxs': y_train_matched.astype(np.int32),\n",
    "            'X_train_unmatched_idxs': X_train_unmatched.astype(np.int32),\n",
    "            'y_train_unmatched_idxs': y_train_unmatched.astype(np.int32),\n",
    "            'X_valid_matched_idxs': X_valid_matched.astype(np.int32),\n",
    "            'y_valid_matched_idxs': y_valid_matched.astype(np.int32),\n",
    "            'X_valid_unmatched_idxs': X_valid_unmatched.astype(np.int32),\n",
    "            'y_valid_unmatched_idxs': y_valid_unmatched.astype(np.int32),\n",
    "            'X_test_matched_idxs': X_test_matched.astype(np.int32),\n",
    "            'y_test_matched_idxs': y_test_matched.astype(np.int32),\n",
    "            'X_test_unmatched_idxs': X_test_unmatched.astype(np.int32),\n",
    "            'y_test_unmatched_idxs': y_test_unmatched.astype(np.int32)\n",
    "        }\n",
    "    else:\n",
    "        # Make pairs of actual and imposter faces\n",
    "        X_train_matched, y_train_matched, X_train_unmatched, y_train_unmatched = make_image_pairs(\n",
    "            X, y, unique_train_labels)\n",
    "        X_valid_matched, y_valid_matched, X_valid_unmatched, y_valid_unmatched = make_image_pairs(\n",
    "            X, y, unique_valid_labels)\n",
    "        X_test_matched, y_test_matched, X_test_unmatched, y_test_unmatched = make_image_pairs(\n",
    "            X, y, unique_test_labels)\n",
    "\n",
    "        return {\n",
    "            'X_train_matched': lasagne.utils.floatX(X_train_matched),\n",
    "            'y_train_matched': y_train_matched.astype(np.int32),\n",
    "            'X_train_unmatched': lasagne.utils.floatX(X_train_unmatched),\n",
    "            'y_train_unmatched': y_train_unmatched.astype(np.int32),\n",
    "            'X_valid_matched': lasagne.utils.floatX(X_valid_matched),\n",
    "            'y_valid_matched': y_valid_matched.astype(np.int32),\n",
    "            'X_valid_unmatched': lasagne.utils.floatX(X_valid_unmatched),\n",
    "            'y_valid_unmatched': y_valid_unmatched.astype(np.int32),\n",
    "            'X_test_matched': lasagne.utils.floatX(X_test_matched),\n",
    "            'y_test_matched': y_test_matched.astype(np.int32),\n",
    "            'X_test_unmatched': lasagne.utils.floatX(X_test_unmatched),\n",
    "            'y_test_unmatched': y_test_unmatched.astype(np.int32)\n",
    "        }\n",
    "\n",
    "\n",
    "def interleave_dataset(X_split, y_split):\n",
    "\n",
    "    # TODO: account for color images\n",
    "    n_batch, n_channels, n_height, n_width = X_split.shape\n",
    "    n_obs = n_batch * n_channels\n",
    "    n_feats = n_height * n_width\n",
    "\n",
    "    X_interleaved = np.empty((n_obs, n_feats), dtype=theano.config.floatX)\n",
    "    y_interleaved = np.empty((n_obs,), dtype=np.int32)\n",
    "\n",
    "    X_interleaved[0::2] = X_split[:, 0, ...].reshape(n_batch, n_feats)\n",
    "    X_interleaved[1::2] = X_split[:, 1, ...].reshape(n_batch, n_feats)\n",
    "\n",
    "    y_interleaved[0::2] = y_split.copy()\n",
    "    y_interleaved[1::2] = y_split.copy()\n",
    "\n",
    "    return X_interleaved.reshape(n_obs, 1, n_height, n_width), y_interleaved\n",
    "\n",
    "\n",
    "def shuffle_dataset(X, y):\n",
    "    indices = np.random.permutation(len(y))\n",
    "    return X[indices, ...], y[indices, ...]\n",
    "\n",
    "\n",
    "def get_balanced_shuffled_dataset(X_matched, y_matched, X_unmatched, y_unmatched):\n",
    "    npairs = X_matched.shape[0]\n",
    "\n",
    "    # Shuffle order\n",
    "    X_matched, y_matched = shuffle_dataset(X_matched, y_matched)\n",
    "    X_unmatched, y_unmatched = shuffle_dataset(X_unmatched, y_unmatched)\n",
    "\n",
    "    # Sample same number of unmatched data\n",
    "    X_train = np.concatenate((X_matched, X_unmatched[:npairs]))\n",
    "    y_train = np.concatenate((y_matched, y_unmatched[:npairs]))\n",
    "\n",
    "    # Shuffle again so that batches aren't all matched/unmatched\n",
    "    X_train, y_train = shuffle_dataset(X_train, y_train)\n",
    "\n",
    "    return X_train, y_train\n",
    "\n",
    "\n",
    "def make_shared(X, dtype):\n",
    "    return theano.shared(np.asarray(X, dtype=dtype), borrow=True)\n",
    "\n",
    "\n",
    "def generate_new_dataset_batch(X_matched, y_matched, X_unmatched, y_unmatched, batch_size):\n",
    "    # Generate a new shuffled, balanced dataset\n",
    "    X_train, y_train = get_balanced_shuffled_dataset(\n",
    "        X_matched, y_matched, X_unmatched, y_unmatched)\n",
    "\n",
    "    # Interleave pairs into sequential batches which will be used in the\n",
    "    # distance/loss functions appropriately\n",
    "    X_train, y_train = interleave_dataset(X_train, y_train)\n",
    "\n",
    "    nobs = len(X_train)\n",
    "\n",
    "    # Make sure it is even\n",
    "    batch_size = batch_size + (batch_size % 2)\n",
    "\n",
    "    # Loop until we're out of observations\n",
    "    batch_start = 0\n",
    "    batch_end = batch_size\n",
    "    while batch_start < np.min((nobs, (nobs - batch_size))):\n",
    "        yield X_train[batch_start:batch_end, ...], y_train[batch_start:batch_end, ...]\n",
    "        batch_start = batch_end\n",
    "        batch_end = batch_start + batch_size\n",
    "\n",
    "\n",
    "def generate_new_dataset_batch_from_idxs(\n",
    "        X, y, X_matched_idxs, y_matched_idxs,\n",
    "        X_unmatched_idxs, y_unmatched_idxs, batch_size):\n",
    "    # Generate a new shuffled, balanced dataset\n",
    "    X_train, y_train = get_balanced_shuffled_dataset(\n",
    "        X_matched_idxs, y_matched_idxs, X_unmatched_idxs, y_unmatched_idxs)\n",
    "\n",
    "    # Interleave pairs into sequential batches which will be used in the distance/loss functions appropriately\n",
    "    # TODO: account for color images\n",
    "    X_train, y_train = interleave_dataset(\n",
    "        X_train[..., np.newaxis, np.newaxis], y_train)\n",
    "    X_train = np.squeeze(X_train).astype(np.int32)\n",
    "    y_train = np.squeeze(y_train).astype(np.int32)\n",
    "\n",
    "    nobs = len(X_train)\n",
    "\n",
    "    # Make sure it is even\n",
    "    batch_size = batch_size + (batch_size % 2)\n",
    "\n",
    "    # Loop until we're out of observations\n",
    "    batch_start = 0\n",
    "    batch_end = batch_size\n",
    "    while batch_start < np.min((nobs, (nobs - batch_size))):\n",
    "        yield X[X_train[batch_start:batch_end, ...], ...], y_train[batch_start:batch_end, ...]\n",
    "        batch_start = batch_end\n",
    "        batch_end = batch_start + batch_size\n",
    "\n",
    "\n",
    "class SiameseNetPredictor(object):\n",
    "\n",
    "    def __init__(self, images, filename='images'):\n",
    "        \"\"\"Summary\"\"\"\n",
    "        # Load the pretrained model\n",
    "        self.result = pickle.load(open(filename, 'rb'))\n",
    "        print(self.result['params'])\n",
    "        self.grayscale = self.result['params']['b_convert_to_grayscale']\n",
    "        self.normalization = self.result['params']['normalization']\n",
    "        self.net = ConvSiameseNet(\n",
    "            input_channels=(1\n",
    "                            if self.grayscale\n",
    "                            else 3),\n",
    "            input_width=self.result['params']['resolution'][0],\n",
    "            input_height=self.result['params']['resolution'][1],\n",
    "            n_out=self.result['params']['n_features'],\n",
    "            distance_fn=self.result['params']['distance_fn'],\n",
    "            nonlinearity=self.result['params']['nonlinearity'])\n",
    "\n",
    "        if self.result['params']['model_type'] == 'custom':\n",
    "            self.net.use_custom_model()\n",
    "        elif self.result['params']['model_type'] == 'hani':\n",
    "            self.net.use_hani_model()\n",
    "        elif self.result['params']['model_type'] == 'chopra':\n",
    "            self.net.use_chopra_model()\n",
    "        else:\n",
    "            print('Unrecognized model!')\n",
    "\n",
    "        self.net.set_from_parameters(\n",
    "            pickle.loads(self.result['model_parameters']))\n",
    "        pred = lasagne.layers.get_output(self.net.model, self.net.x,\n",
    "                                         deterministic=True)\n",
    "\n",
    "        # Compile\n",
    "        self.fn = theano.function([self.net.x], [pred])\n",
    "\n",
    "        # We'll hash functions for every layer if/when user asks for them\n",
    "        self.fns = {}\n",
    "\n",
    "        # Train final regressor on entire dataset\n",
    "        # (cheating, but...Â¯\\_(ãƒ„)_/Â¯)\n",
    "        Xs = self.result['prediction']['X']\n",
    "        ys = self.result['prediction']['y']\n",
    "        Xs_L1 = np.abs(Xs[:, :self.net.n_out] - Xs[:, self.net.n_out:])\n",
    "        self.clf = LogisticRegression()\n",
    "        self.clf.fit(Xs_L1, ys)\n",
    "\n",
    "        # Load normalization kernel\n",
    "        # (previously created using LCN on the training set)\n",
    "        # self.lcn = pickle.loads(self.result['LCN'])\n",
    "        if self.grayscale:\n",
    "            X = np.concatenate([img[np.newaxis, np.newaxis, ...]\n",
    "                                for img in images], axis=0)\n",
    "        else:\n",
    "            X = np.concatenate([img[np.newaxis, ...]\n",
    "                                for img in images], axis=0)\n",
    "        print(X.shape)\n",
    "\n",
    "        if self.normalization == 'LCN':\n",
    "            lcn = LCN(\n",
    "                sigma=round(0.0625 * self.result['params']['resolution'][0]),\n",
    "                subtractive=False)\n",
    "            lcn.fit(X)\n",
    "            self.norm = lcn\n",
    "        elif self.normalization == 'LCN-':\n",
    "            lcn = LCN(\n",
    "                sigma=round(0.0625 * self.result['params']['resolution'][0]),\n",
    "                subtractive=True)\n",
    "            lcn.fit(X)\n",
    "            self.norm = lcn\n",
    "        elif self.normalization == 'ZCA':\n",
    "            zca = ZCA(bias=0.1)\n",
    "            zca.fit(X)\n",
    "            self.norm = zca\n",
    "        elif self.normalization == '-1:1':\n",
    "            self.norm = lambda x: ((x - np.min(x)) / (np.max(x) - np.min(x)) * 2.0 - 1.0)\n",
    "\n",
    "    def preprocess(self, X):\n",
    "        res = None\n",
    "        try:\n",
    "            res = self.norm.transform(X)\n",
    "        except:\n",
    "            res = self.norm(X)\n",
    "            pass\n",
    "        return res\n",
    "\n",
    "    def features_for_layer(self, X, layer_num):\n",
    "        if layer_num in self.fns.keys():\n",
    "            fn = self.fns[layer_num]\n",
    "        else:\n",
    "            layer_output = lasagne.layers.get_output(\n",
    "                lasagne.layers.get_all_layers(\n",
    "                    self.net.model)[layer_num],\n",
    "                self.net.x, deterministic=True)\n",
    "            fn = theano.function([self.net.x], [layer_output])\n",
    "            self.fns[layer_num] = fn\n",
    "        out = fn(lasagne.utils.floatX(X))\n",
    "        return out\n",
    "\n",
    "    def features(self, X):\n",
    "        return self.fn(X)\n",
    "\n",
    "    def predict(self, X):\n",
    "        features = self.fn(X)\n",
    "        Xs_L1 = np.abs(features[0][0::2] - features[0][1::2])\n",
    "        final = self.clf.predict(Xs_L1)\n",
    "        return final\n",
    "\n",
    "    def get_normalization(self):\n",
    "        return self.result['params']['normalization']\n",
    "\n",
    "    def get_crop(self):\n",
    "        '''Return the crop type of the pre-trained network.'''\n",
    "        return self.result['params']['crop']\n",
    "\n",
    "    def get_resolution(self):\n",
    "        return self.result['params']['resolution']\n",
    "\n",
    "    def get_colorscale(self):\n",
    "        return self.result['params']['b_convert_to_grayscale']\n",
    "\n",
    "\n",
    "class ConvSiameseNet:\n",
    "\n",
    "    def __init__(self,\n",
    "                 input_channels,\n",
    "                 input_width,\n",
    "                 input_height,\n",
    "                 n_out,\n",
    "                 batch_size=None,\n",
    "                 distance_fn='l1',\n",
    "                 nonlinearity='scaled_tanh'):\n",
    "        self.input_channels = input_channels\n",
    "        self.input_width = input_width\n",
    "        self.input_height = input_height\n",
    "        self.n_out = n_out\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.l_in = lasagne.layers.InputLayer(\n",
    "            shape=(None, input_channels, input_width, input_height))\n",
    "        self.n_out = n_out\n",
    "\n",
    "        self.srng = theano.sandbox.rng_mrg.MRG_RandomStreams()\n",
    "\n",
    "        self.loss_fn = contrastive_loss\n",
    "        if distance_fn.lower() == 'cosine':\n",
    "            self.distance_fn = distance_cosine\n",
    "        elif distance_fn.lower() == 'l1':\n",
    "            self.distance_fn = distance_L1\n",
    "        elif distance_fn.lower() == 'l2':\n",
    "            self.distance_fn = distance_L2\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                'Must specify distance as either \"cosine\", \"l1\", or \"l2\".')\n",
    "\n",
    "        self.x = T.tensor4('x')\n",
    "        self.y = T.ivector('y')\n",
    "\n",
    "        if nonlinearity == 'scaled_tanh':\n",
    "            self.nonlinearity = lasagne.nonlinearities.ScaledTanH(\n",
    "                scale_in=2. / 3, scale_out=1.7159)\n",
    "        elif nonlinearity == 'rectify':\n",
    "            self.nonlinearity = lasagne.nonlinearities.rectify\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                'Must specify nonlinearity as either \"scaled_tanh\" or \"rectify\".')\n",
    "\n",
    "        self.weight_init = lasagne.init.Normal(std=0.05, mean=0.0)\n",
    "\n",
    "    def use_hani_model(self, dropout_pct=0.0, b_spatial=False):\n",
    "        self.model = self.get_hani_2014_net(\n",
    "            self.l_in, dropout_pct=dropout_pct, b_spatial=b_spatial)\n",
    "\n",
    "    def use_custom_model(self, b_spatial=False):\n",
    "        self.model = self.get_custom_net(self.l_in, b_spatial=b_spatial)\n",
    "\n",
    "    def use_chopra_model(self, dropout_pct=0.0, b_spatial=False):\n",
    "        self.model = self.get_chopra_net(\n",
    "            self.l_in, dropout_pct=dropout_pct, b_spatial=b_spatial)\n",
    "\n",
    "    def use_deepid_model(self, b_spatial=False):\n",
    "        self.model = self.get_deep_id_net(self.l_in, b_spatial=b_spatial)\n",
    "\n",
    "    def get_spatial_transform_net(self, input_layer):\n",
    "        # http://lasagne.readthedocs.org/en/latest/modules/layers/special.html?highlight=trainable#lasagne.layers.TransformerLayer\n",
    "        # Localization network\n",
    "        # Spatial Transformer Networks Max Jaderberg, Karen Simonyan, Andrew Zisserman, Koray Kavukcuoglu Submitted on 5 Jun 2015\n",
    "        # Here we set up the layer to initially do the identity transform,\n",
    "        # similarly to [R34]. Note that you will want to use a localization\n",
    "        # with linear output. If the output from the localization networks\n",
    "        # is [t1, t2, t3, t4, t5, t6] then t1 and t5 determines zoom, t2\n",
    "        # and t4 determines skewness, and t3 and t6 move the center\n",
    "        # position.\n",
    "\n",
    "        b = np.zeros((2, 3), dtype=theano.config.floatX)\n",
    "        b[0, 0] = 1\n",
    "        b[1, 1] = 1\n",
    "        b = b.flatten()\n",
    "        loc_l1 = lasagne.layers.MaxPool2DLayer(input_layer, pool_size=(2, 2))\n",
    "        loc_l2 = lasagne.layers.Conv2DLayer(\n",
    "            loc_l1,\n",
    "            num_filters=20,\n",
    "            filter_size=(5, 5),\n",
    "            W=self.weight_init\n",
    "        )\n",
    "        loc_l3 = lasagne.layers.MaxPool2DLayer(loc_l2, pool_size=(2, 2))\n",
    "        loc_l4 = lasagne.layers.Conv2DLayer(\n",
    "            loc_l3,\n",
    "            num_filters=20,\n",
    "            filter_size=(5, 5),\n",
    "            W=self.weight_init\n",
    "        )\n",
    "        loc_l5 = lasagne.layers.DenseLayer(\n",
    "            loc_l4,\n",
    "            num_units=50,\n",
    "            W=self.weight_init\n",
    "        )\n",
    "        loc_out = lasagne.layers.DenseLayer(\n",
    "            loc_l5,\n",
    "            num_units=6,\n",
    "            b=b,\n",
    "            W=self.weight_init,\n",
    "            nonlinearity=lasagne.nonlinearities.identity\n",
    "        )\n",
    "\n",
    "        # Transformer network\n",
    "        transformed_input_layer = lasagne.layers.TransformerLayer(\n",
    "            input_layer, loc_out, downsample_factor=2.0)\n",
    "        print('Transformed Input Shape: ',\n",
    "              transformed_input_layer.output_shape)\n",
    "        return transformed_input_layer\n",
    "\n",
    "    def get_chopra_net(self, input_layer, dropout_pct=0.0, b_spatial=False):\n",
    "\n",
    "        l_conv1 = None\n",
    "\n",
    "        if b_spatial:\n",
    "            # returns a 15x40x40\n",
    "            l_conv1 = lasagne.layers.Conv2DLayer(\n",
    "                self.get_spatial_transform_net(input_layer),\n",
    "                num_filters=15,\n",
    "                filter_size=(7, 7),\n",
    "                nonlinearity=self.nonlinearity,\n",
    "                W=self.weight_init\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            # returns a 15x40x40\n",
    "            l_conv1 = lasagne.layers.Conv2DLayer(\n",
    "                input_layer,\n",
    "                num_filters=15,\n",
    "                filter_size=(7, 7),\n",
    "                nonlinearity=self.nonlinearity,\n",
    "                W=self.weight_init\n",
    "            )\n",
    "\n",
    "        # returns a 15x20x20\n",
    "        l_pool1 = lasagne.layers.MaxPool2DLayer(l_conv1, pool_size=(2, 2))\n",
    "\n",
    "        # returns a 45x15x15\n",
    "        l_conv2 = lasagne.layers.Conv2DLayer(\n",
    "            l_pool1,\n",
    "            num_filters=45,\n",
    "            filter_size=(6, 6),\n",
    "            nonlinearity=self.nonlinearity,\n",
    "            W=self.weight_init\n",
    "        )\n",
    "\n",
    "        # returns a 45x5x5\n",
    "        l_pool2 = lasagne.layers.MaxPool2DLayer(l_conv2, pool_size=(3, 3))\n",
    "        l_pool2_dropout = lasagne.layers.DropoutLayer(l_pool2, p=dropout_pct)\n",
    "\n",
    "        # returns a 250x1x1\n",
    "        l_conv3 = lasagne.layers.Conv2DLayer(\n",
    "            l_pool2_dropout,\n",
    "            num_filters=250,\n",
    "            filter_size=(5, 5),\n",
    "            nonlinearity=self.nonlinearity,\n",
    "            W=self.weight_init\n",
    "        )\n",
    "\n",
    "        l_hidden = lasagne.layers.DenseLayer(\n",
    "            l_conv3,\n",
    "            num_units=self.n_out,\n",
    "            nonlinearity=self.nonlinearity,\n",
    "            W=self.weight_init\n",
    "        )\n",
    "\n",
    "        model = lasagne.layers.DenseLayer(\n",
    "            l_hidden,\n",
    "            num_units=self.n_out,\n",
    "            nonlinearity=self.nonlinearity,\n",
    "            W=self.weight_init\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "    def get_custom_net(self, input_layer, b_spatial=False):\n",
    "        l_conv1a = None\n",
    "\n",
    "        if b_spatial:\n",
    "            l_conv1a = lasagne.layers.Conv2DLayer(\n",
    "                self.get_spatial_transform_net(input_layer),\n",
    "                num_filters=16,\n",
    "                filter_size=(3, 3),\n",
    "                nonlinearity=self.relu,\n",
    "                W=self.weight_init\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            l_conv1a = lasagne.layers.Conv2DLayer(\n",
    "                input_layer,\n",
    "                num_filters=16,\n",
    "                filter_size=(3, 3),\n",
    "                nonlinearity=self.nonlinearity,\n",
    "                W=self.weight_init\n",
    "            )\n",
    "\n",
    "        l_conv1b = lasagne.layers.Conv2DLayer(\n",
    "            l_conv1a,\n",
    "            num_filters=32,\n",
    "            filter_size=(3, 3),\n",
    "            nonlinearity=self.nonlinearity,\n",
    "            W=self.weight_init\n",
    "        )\n",
    "        l_pool1 = lasagne.layers.MaxPool2DLayer(l_conv1b, pool_size=(2, 2))\n",
    "\n",
    "        l_conv2a = lasagne.layers.Conv2DLayer(\n",
    "            l_pool1,\n",
    "            num_filters=32,\n",
    "            filter_size=(3, 3),\n",
    "            nonlinearity=self.nonlinearity,\n",
    "            W=self.weight_init\n",
    "        )\n",
    "        l_conv2b = lasagne.layers.Conv2DLayer(\n",
    "            l_conv2a,\n",
    "            num_filters=64,\n",
    "            filter_size=(3, 3),\n",
    "            nonlinearity=self.nonlinearity,\n",
    "            W=self.weight_init\n",
    "        )\n",
    "        l_pool2 = lasagne.layers.MaxPool2DLayer(l_conv2b, pool_size=(2, 2))\n",
    "\n",
    "        l_conv3a = lasagne.layers.Conv2DLayer(\n",
    "            l_pool2,\n",
    "            num_filters=64,\n",
    "            filter_size=(3, 3),\n",
    "            nonlinearity=self.nonlinearity,\n",
    "            W=self.weight_init\n",
    "        )\n",
    "\n",
    "        l_conv3b = lasagne.layers.Conv2DLayer(\n",
    "            l_conv3a,\n",
    "            num_filters=128,\n",
    "            filter_size=(3, 3),\n",
    "            nonlinearity=self.nonlinearity,\n",
    "            W=self.weight_init\n",
    "        )\n",
    "\n",
    "        l_pool3 = lasagne.layers.MaxPool2DLayer(l_conv3b, pool_size=(2, 2))\n",
    "        l_full4 = lasagne.layers.DenseLayer(\n",
    "            l_pool3,\n",
    "            num_units=self.n_out,\n",
    "            nonlinearity=self.nonlinearity,\n",
    "            W=self.weight_init\n",
    "        )\n",
    "\n",
    "        model = lasagne.layers.DenseLayer(\n",
    "            l_full4,\n",
    "            num_units=self.n_out,\n",
    "            nonlinearity=self.nonlinearity,\n",
    "            W=self.weight_init\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "    # this model actually requires a different training procedure, of\n",
    "    # recognition then verification\n",
    "    def get_deep_id_net(self, input_layer, b_spatial=False):\n",
    "        l_conv1 = None\n",
    "        # flip = False\n",
    "\n",
    "        # returns a 20x52x44\n",
    "        if b_spatial:\n",
    "            l_conv1 = lasagne.layers.Conv2DLayer(\n",
    "                self.get_spatial_transform_net(input_layer),\n",
    "                num_filters=20,\n",
    "                filter_size=(4, 4),\n",
    "                stride=(1, 1),\n",
    "                nonlinearity=self.nonlinearity,\n",
    "                W=self.weight_init\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            l_conv1 = lasagne.layers.Conv2DLayer(\n",
    "                input_layer,\n",
    "                num_filters=20,\n",
    "                filter_size=(4, 4),\n",
    "                stride=(1, 1),\n",
    "                nonlinearity=self.nonlinearity,\n",
    "                W=self.weight_init\n",
    "            )\n",
    "        l_pool1 = lasagne.layers.MaxPool2DLayer(l_conv1, pool_size=(3, 3))\n",
    "\n",
    "        l_conv2 = lasagne.layers.Conv2DLayer(\n",
    "            l_pool1,\n",
    "            num_filters=40,\n",
    "            filter_size=(3, 3),\n",
    "            stride=(1, 1),\n",
    "            nonlinearity=self.nonlinearity,\n",
    "            W=self.weight_init\n",
    "        )\n",
    "        l_pool2 = lasagne.layers.MaxPool2DLayer(l_conv2, pool_size=(3, 3))\n",
    "\n",
    "        l_conv3 = lasagne.layers.Conv2DLayer(\n",
    "            l_pool2,\n",
    "            num_filters=60,\n",
    "            filter_size=(3, 3),\n",
    "            stride=(1, 1),\n",
    "            nonlinearity=self.nonlinearity,\n",
    "            W=self.weight_init\n",
    "        )\n",
    "        l_pool3 = lasagne.layers.MaxPool2DLayer(l_conv3, pool_size=(3, 3))\n",
    "\n",
    "        l_conv4 = lasagne.layers.Conv2DLayer(\n",
    "            l_pool3,\n",
    "            num_filters=80,\n",
    "            filter_size=(2, 2),\n",
    "            stride=(1, 1),\n",
    "            nonlinearity=self.nonlinearity,\n",
    "            W=self.weight_init\n",
    "        )\n",
    "\n",
    "        model = lasagne.layers.DenseLayer(\n",
    "            l_conv4,\n",
    "            num_units=self.n_out,\n",
    "            nonlinearity=self.nonlinearity,\n",
    "            W=self.weight_init\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "    def get_deep_id2_plus_net(self, input_layer, b_spatial=False):\n",
    "        l_conv1 = None\n",
    "        # flip = False\n",
    "\n",
    "        # returns a 20x52x44\n",
    "        if b_spatial:\n",
    "            l_conv1 = lasagne.layers.Conv2DLayer(\n",
    "                self.get_spatial_transform_net(input_layer),\n",
    "                num_filters=128,\n",
    "                filter_size=(3, 4, 4),\n",
    "                stride=(1, 1),\n",
    "                nonlinearity=self.nonlinearity,\n",
    "                W=self.weight_init\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            l_conv1 = lasagne.layers.Conv2DLayer(\n",
    "                input_layer,\n",
    "                num_filters=128,\n",
    "                filter_size=(3, 4, 4),\n",
    "                stride=(1, 1),\n",
    "                nonlinearity=self.nonlinearity,\n",
    "                W=self.weight_init\n",
    "            )\n",
    "        l_pool1 = lasagne.layers.MaxPool2DLayer(l_conv1, pool_size=(3, 3))\n",
    "\n",
    "        l_conv2 = lasagne.layers.Conv2DLayer(\n",
    "            l_pool1,\n",
    "            num_filters=128,\n",
    "            filter_size=(3, 3),\n",
    "            stride=(1, 1),\n",
    "            nonlinearity=self.nonlinearity,\n",
    "            W=self.weight_init\n",
    "        )\n",
    "        l_pool2 = lasagne.layers.MaxPool2DLayer(l_conv2, pool_size=(3, 3))\n",
    "\n",
    "        l_conv3 = lasagne.layers.Conv2DLayer(\n",
    "            l_pool2,\n",
    "            num_filters=128,\n",
    "            filter_size=(3, 3),\n",
    "            stride=(1, 1),\n",
    "            nonlinearity=self.nonlinearity,\n",
    "            W=self.weight_init\n",
    "        )\n",
    "        l_pool3 = lasagne.layers.MaxPool2DLayer(l_conv3, pool_size=(3, 3))\n",
    "\n",
    "        l_conv4 = lasagne.layers.Conv2DLayer(\n",
    "            l_pool3,\n",
    "            num_filters=128,\n",
    "            filter_size=(2, 2),\n",
    "            stride=(1, 1),\n",
    "            nonlinearity=self.nonlinearity,\n",
    "            W=self.weight_init\n",
    "        )\n",
    "\n",
    "        model = lasagne.layers.DenseLayer(\n",
    "            l_conv4,\n",
    "            num_units=self.n_out,\n",
    "            nonlinearity=self.nonlinearity,\n",
    "            W=self.weight_init\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "    def get_hani_2014_net(self, input_layer, dropout_pct=0.5, b_spatial=False):\n",
    "\n",
    "        # from lasagne.layers.corrmm import Conv2DMMLayer\n",
    "\n",
    "        l_conv1 = None\n",
    "        # flip = False\n",
    "\n",
    "        if b_spatial:\n",
    "            # returns a 5x21x21\n",
    "            l_conv1 = lasagne.layers.Conv2DLayer(\n",
    "                self.get_spatial_transform_net(input_layer),\n",
    "                num_filters=5,\n",
    "                filter_size=(6, 6),\n",
    "                stride=(2, 2),\n",
    "                nonlinearity=self.nonlinearity,\n",
    "                # flip_filters=flip,\n",
    "                W=self.weight_init\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            # returns a 5x21x21\n",
    "            l_conv1 = lasagne.layers.Conv2DLayer(\n",
    "                input_layer,\n",
    "                num_filters=5,\n",
    "                filter_size=(6, 6),\n",
    "                stride=(2, 2),\n",
    "                nonlinearity=self.nonlinearity,\n",
    "                # flip_filters=flip,\n",
    "                W=self.weight_init\n",
    "            )\n",
    "\n",
    "        # returns a 14x6x6\n",
    "        l_conv2 = lasagne.layers.Conv2DLayer(\n",
    "            l_conv1,\n",
    "            num_filters=14,\n",
    "            filter_size=(6, 6),\n",
    "            stride=(2, 2),\n",
    "            nonlinearity=self.nonlinearity,\n",
    "            # flip_filters=flip,\n",
    "            W=self.weight_init\n",
    "        )\n",
    "\n",
    "        l_dropout2 = lasagne.layers.DropoutLayer(l_conv2, p=dropout_pct)\n",
    "\n",
    "        # returns a 60x1x1\n",
    "        l_conv3 = lasagne.layers.Conv2DLayer(\n",
    "            l_dropout2,\n",
    "            num_filters=60,\n",
    "            filter_size=(6, 6),\n",
    "            nonlinearity=self.nonlinearity,\n",
    "            # flip_filters=flip,\n",
    "            W=self.weight_init\n",
    "        )\n",
    "\n",
    "        l_hidden = lasagne.layers.DenseLayer(\n",
    "            l_conv3,\n",
    "            num_units=self.n_out,\n",
    "            nonlinearity=self.nonlinearity,\n",
    "            W=self.weight_init\n",
    "        )\n",
    "\n",
    "        model = lasagne.layers.DenseLayer(\n",
    "            l_hidden,\n",
    "            num_units=self.n_out,\n",
    "            nonlinearity=lasagne.nonlinearities.identity,\n",
    "            W=lasagne.init.Uniform()\n",
    "        )\n",
    "\n",
    "        return model\n",
    "\n",
    "    def build_model(self,\n",
    "                    X_train,\n",
    "                    y_train,\n",
    "                    X_valid,\n",
    "                    y_valid,\n",
    "                    X_test,\n",
    "                    y_test,\n",
    "                    update=lasagne.updates.adam,\n",
    "                    hyperparameter_margin=2.0,\n",
    "                    hyperparameter_threshold=5.0,\n",
    "                    learning_rate=0.0001):\n",
    "\n",
    "        self.learning_rate = theano.shared(lasagne.utils.floatX(learning_rate))\n",
    "        self.hyperparameter_threshold = lasagne.utils.floatX(\n",
    "            hyperparameter_threshold)\n",
    "        self.hyperparameter_margin = lasagne.utils.floatX(\n",
    "            hyperparameter_margin)\n",
    "\n",
    "        self.train_x = X_train\n",
    "        self.validation_x = X_valid\n",
    "        self.test_x = X_test\n",
    "\n",
    "        self.update = update\n",
    "\n",
    "        self.index = T.iscalar('index')\n",
    "        self.batch_slice = slice(\n",
    "            self.index * self.batch_size, (self.index + 1) * self.batch_size)\n",
    "\n",
    "        # Training Loss\n",
    "        y_pred = lasagne.layers.get_output(\n",
    "            self.model, self.x, deterministic=False)\n",
    "        avg_loss = self.loss_fn(y_pred, self.y, self.hyperparameter_margin)\n",
    "        loss = avg_loss / self.batch_size\n",
    "\n",
    "        # Validation Loss\n",
    "        y_pred_eval = lasagne.layers.get_output(\n",
    "            self.model, self.x, deterministic=True)\n",
    "        avg_loss = self.loss_fn(\n",
    "            y_pred_eval, self.y, self.hyperparameter_margin)\n",
    "        loss_eval = avg_loss / self.batch_size\n",
    "        # loss_eval = loss_eval.mean()\n",
    "\n",
    "        # Validation Accuracy\n",
    "        pred = self.distance_fn(y_pred_eval)\n",
    "        accuracy = T.mean(T.eq(T.lt(pred, self.hyperparameter_threshold), self.y[\n",
    "                          0::2]), dtype=theano.config.floatX)\n",
    "\n",
    "        # Find weight params to update during backprop, and use adam updater\n",
    "        all_params = lasagne.layers.get_all_params(self.model, trainable=True)\n",
    "        updates = lasagne.updates.adam(\n",
    "            loss, all_params, learning_rate=self.learning_rate)\n",
    "\n",
    "        # Setup each model and return\n",
    "        train_model = theano.function(\n",
    "            [self.x, self.y], [loss, y_pred], updates=updates)\n",
    "        validate_model = theano.function(\n",
    "            [self.x, self.y], [loss_eval, accuracy, y_pred_eval])\n",
    "        test_model = theano.function(\n",
    "            [self.x, self.y], [loss_eval, accuracy, y_pred_eval])\n",
    "\n",
    "        return train_model, validate_model, test_model\n",
    "\n",
    "    def get_evaluation_model(self):\n",
    "        \n",
    "        y_pred = lasagne.layers.get_output(\n",
    "            self.model, self.x, deterministic=True)\n",
    "        fn = theano.function([self.x], [y_pred])\n",
    "        return fn\n",
    "\n",
    "    def retrieve_parameters(self):\n",
    "        return lasagne.layers.get_all_param_values(self.model)\n",
    "\n",
    "    def set_from_parameters(self, parameters):\n",
    "        lasagne.layers.set_all_param_values(self.model, parameters)\n",
    "\n",
    "    def load_model(self, filename='model.pkl'):\n",
    "        params = pickle.load(open(filename, 'rb'))\n",
    "        lasagne.layers.set_all_param_values(self.model, params)\n",
    "\n",
    "    def save_model(self, filename='model.pkl'):\n",
    "        params = lasagne.layers.get_all_param_values(self.model)\n",
    "        pickle.dump(params, open(filename, 'wb'))\n",
    "\n",
    "    def get_learning_rate(self):\n",
    "        return self.learning_rate.get_value()\n",
    "\n",
    "    def set_learning_rate(self, lr):\n",
    "        self.learning_rate.set_value(lasagne.utils.floatX(lr))\n",
    "\n",
    "\n",
    "def distance_L2(x):\n",
    "    x_a = x[0::2]\n",
    "    x_b = x[1::2]\n",
    "    return T.sum((x_a - x_b)**2, axis=1)\n",
    "\n",
    "\n",
    "def distance_L1(x):\n",
    "    x_a = x[0::2]\n",
    "    x_b = x[1::2]\n",
    "    return T.sum(T.abs_(x_a - x_b), axis=1)\n",
    "\n",
    "\n",
    "def l2norm(x):\n",
    "    return T.sqrt(T.sum(T.sqr(x), axis=1))\n",
    "\n",
    "\n",
    "def distance_cosine(x, e=1e-6):\n",
    "    x_a = x[0::2]\n",
    "    x_b = x[1::2]\n",
    "    return T.sum(x_a * x_b, axis=1) / T.maximum(l2norm(x_a) * l2norm(x_b), e)\n",
    "\n",
    "\n",
    "# def contrastive_loss(y_pred, y_true, Q=20.0):\n",
    "# eq. 8\n",
    "#     E_w = distance_L1(y_pred)\n",
    "#     y = y_true[0::2]\n",
    "# eq 9\n",
    "# Decrease energy for matched pair: (0 = unmatched, 1 = matched)\n",
    "#     L_G = (1.0 - y) * (2.0 / Q) * (E_w ** 2)\n",
    "#     L_I = (y) * 2.0 * Q * T.exp((-2.7726 * E_w) / Q)\n",
    "#     L = L_G + L_I\n",
    "#     avg_loss = T.mean(L)\n",
    "#     return avg_loss\n",
    "\n",
    "\n",
    "def contrastive_loss(y_pred, y_true, margin=20.0):\n",
    "    x1 = y_pred[0::2]\n",
    "    x2 = y_pred[1::2]\n",
    "\n",
    "    d = T.sum((x1 - x2)**2, axis=1)\n",
    "    y = y_true[0::2]\n",
    "    return T.mean(y * d + (1.0 - y) * T.maximum(margin - d, 0.0))\n",
    "\n",
    "\n",
    "def continue_siamese_net_training(filename):\n",
    "    results_file = pickle.load(open(filename, 'rb'))\n",
    "    params = results_file['params']\n",
    "    print(params)\n",
    "    run_siamese_net_training(\n",
    "        dataset=params['dataset'],\n",
    "        spatial=params['spatial_transform'],\n",
    "        batch_size=params['batch_size'],\n",
    "        n_out=params['n_features'],\n",
    "        model_type=params['model_type'],\n",
    "        n_epochs=params['n_epochs'],\n",
    "        num_files=params['n_files'],\n",
    "        learning_rate=params['learning_rate'],\n",
    "        normalization=params['normalization'],\n",
    "        crop_factor=params['crop'],\n",
    "        resolution=params['resolution'][0],\n",
    "        hyperparameter_margin=params['hyperparameter_margin'],\n",
    "        hyperparameter_threshold=params['hyperparameter_threshold'],\n",
    "        dropout_pct=params['dropout_pct'],\n",
    "        nonlinearity=params['nonlinearity'],\n",
    "        distance_fn=params['distance_fn'],\n",
    "        b_convert_to_grayscale=params['b_convert_to_grayscale'],\n",
    "        filename=filename + 'continued.pkl'\n",
    "    )\n",
    "\n",
    "\n",
    "def run_siamese_net_training(dataset,\n",
    "                             spatial,\n",
    "                             batch_size,\n",
    "                             learning_rate,\n",
    "                             model_type,\n",
    "                             n_epochs,\n",
    "                             n_out,\n",
    "                             num_files,\n",
    "                             normalization,\n",
    "                             resolution,\n",
    "                             crop_factor,\n",
    "                             hyperparameter_margin,\n",
    "                             hyperparameter_threshold,\n",
    "                             nonlinearity,\n",
    "                             distance_fn,\n",
    "                             b_convert_to_grayscale,\n",
    "                             filename=None,\n",
    "                             path_to_data=None,\n",
    "                             b_load_idxs_only=True):\n",
    "    \n",
    "    if filename is None:\n",
    "        filename = str('dataset_%s' % dataset +\n",
    "                       '_transform_%d' % int(spatial) +\n",
    "                       '_batch_%d' % batch_size +\n",
    "                       '_lr_%f' % learning_rate +\n",
    "                       '_model_%s' % model_type +\n",
    "                       '_epochs_%d' % n_epochs +\n",
    "                       '_normalization_%s' % normalization +\n",
    "                       '_cropfactor_%0.02f' % crop_factor +\n",
    "                       '_nout_%d' % n_out +\n",
    "                       '_resolution_%d' % resolution +\n",
    "                       '_numfiles_%d' % num_files +\n",
    "                       '_q_%2.02f' % hyperparameter_margin +\n",
    "                       '_t_%2.02f' % hyperparameter_threshold +\n",
    "                       '_nonlinearity_%s' % nonlinearity +\n",
    "                       '_distancefn_%s' % distance_fn +\n",
    "                       '_grayscale_%d.pkl' % b_convert_to_grayscale)\n",
    "        filename = os.path.join('results', filename)\n",
    "\n",
    "    results = None\n",
    "    model = None\n",
    "    if os.path.isfile(filename):\n",
    "        try:\n",
    "            results = pickle.load(open(filename, 'rb'))\n",
    "            if 'epochs' in results.keys():\n",
    "                if len(results['epochs']) >= n_epochs:\n",
    "                    print('Already process(ing/ed); exiting.')\n",
    "                    return\n",
    "                # else:\n",
    "                # continue where it left off\n",
    "                #     if 'model' in results.keys():\n",
    "                #         model = pickle.loads(results['model'])\n",
    "                #         model.set_from_parameters(pickle.loads(results['model_parameters']))\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    print(\"\"\"Dataset: %s\n",
    "        \\rSpatial: %d\n",
    "        \\rBatch Size: %d\n",
    "        \\rNum Features: %d\n",
    "        \\rModel Type: %s\n",
    "        \\rNum Epochs: %d\n",
    "        \\rNum Files: %d\n",
    "        \\rLearning Rate: %f\n",
    "        \\rNormalization: %s\n",
    "        \\rCrop Factor: %f\n",
    "        \\rResolution: %d\n",
    "        \\rHyperparameter Margin: %f\n",
    "        \\rHyperparameter Threshold: %f\n",
    "        \\rNon-Linearity: %s\n",
    "        \\rGrayscale: %d\n",
    "        \\rDistance Function: %s\\n\n",
    "        \\rWriting results to: %s\\n\"\"\" % (dataset,\n",
    "                                         int(spatial),\n",
    "                                         batch_size,\n",
    "                                         n_out,\n",
    "                                         model_type,\n",
    "                                         n_epochs,\n",
    "                                         num_files,\n",
    "                                         learning_rate,\n",
    "                                         normalization,\n",
    "                                         crop_factor,\n",
    "                                         resolution,\n",
    "                                         hyperparameter_margin,\n",
    "                                         hyperparameter_threshold,\n",
    "                                         nonlinearity,\n",
    "                                         int(b_convert_to_grayscale),\n",
    "                                         distance_fn,\n",
    "                                         filename))\n",
    "\n",
    "    if model_type == 'deepid':\n",
    "        b_convert_to_grayscale = False\n",
    "\n",
    "    if b_convert_to_grayscale:\n",
    "        input_channels = 1\n",
    "    else:\n",
    "        input_channels = 3\n",
    "\n",
    "    # TODO: if continuing a result from a left off epoch, the dataset will\n",
    "    # have been generated differently. how should I handle this?  store the\n",
    "    # pairs, too big a file?  store the rng, what about parameters?\n",
    "    print('Loading dataset...')\n",
    "    data = load_pairs(\n",
    "        dataset=dataset,\n",
    "        normalization=normalization,\n",
    "        resolution=(resolution, resolution),\n",
    "        split=(0.8, 0.2, 0.2),\n",
    "        crop_factor=1.2,\n",
    "        n_files_per_person=num_files,\n",
    "        path_to_data=path_to_data,\n",
    "        b_load_idxs_only=b_load_idxs_only,\n",
    "        b_convert_to_grayscale=b_convert_to_grayscale)\n",
    "\n",
    "    print('Initializing Siamese Network...')\n",
    "    print(data['X'].shape)\n",
    "    X_train = np.zeros(np.hstack((batch_size, data['X'].shape[1:])))\n",
    "    y_train = np.zeros(np.hstack((batch_size, data['y'].shape[1:])))\n",
    "\n",
    "    if model is None:\n",
    "        model = ConvSiameseNet(input_channels=input_channels,\n",
    "                               input_width=X_train.shape[2],\n",
    "                               input_height=X_train.shape[3],\n",
    "                               n_out=n_out,\n",
    "                               batch_size=batch_size,\n",
    "                               nonlinearity=nonlinearity,\n",
    "                               distance_fn=distance_fn)\n",
    "\n",
    "        if model_type == 'hani':\n",
    "            model.use_hani_model(dropout_pct=0.0, b_spatial=spatial)\n",
    "        elif model_type == 'custom':\n",
    "            model.use_custom_model(b_spatial=spatial)\n",
    "        elif model_type == 'chopra':\n",
    "            model.use_chopra_model(\n",
    "                dropout_pct=0.0, b_spatial=spatial)\n",
    "        elif model_type == 'deepid':\n",
    "            model.use_deepid_model(b_spatial=spatial)\n",
    "        else:\n",
    "            print(\n",
    "                'Unrecognized model type! Choose between \\'hani\\', \\'chopra\\', or \\'custom\\'')\n",
    "            sys.exit(2)\n",
    "\n",
    "    train_model, validate_model, test_model = model.build_model(\n",
    "        X_train, y_train,\n",
    "        X_train, y_train,\n",
    "        X_train, y_train,\n",
    "        hyperparameter_margin=hyperparameter_margin,\n",
    "        hyperparameter_threshold=hyperparameter_threshold,\n",
    "        learning_rate=learning_rate\n",
    "    )\n",
    "    if results is None:\n",
    "        results = {\n",
    "            'params':\n",
    "            {\n",
    "                'dataset': dataset,\n",
    "                'spatial_transform': spatial,\n",
    "                'batch_size': batch_size,\n",
    "                'n_features': n_out,\n",
    "                'model_type': model_type,\n",
    "                'n_epochs': n_epochs,\n",
    "                'n_files': num_files,\n",
    "                'learning_rate': learning_rate,\n",
    "                'normalization': normalization,\n",
    "                'crop': crop_factor,\n",
    "                'resolution': (resolution, resolution),\n",
    "                'hyperparameter_margin': hyperparameter_margin,\n",
    "                'hyperparameter_threshold': hyperparameter_threshold,\n",
    "                'nonlinearity': nonlinearity,\n",
    "                'distance_fn': distance_fn,\n",
    "                'b_convert_to_grayscale': b_convert_to_grayscale\n",
    "            },\n",
    "            'epochs': [],\n",
    "            'prediction':\n",
    "            {\n",
    "                'X': None,\n",
    "                'y': None,\n",
    "                'imgs': None,\n",
    "                'auc': [],\n",
    "                'F1': [],\n",
    "                'log_loss': [],\n",
    "                'W': []\n",
    "            },\n",
    "            'model': None,\n",
    "            'model_parameters': None\n",
    "        }\n",
    "\n",
    "    delta_loss = 1.0\n",
    "    epoch = len(results['epochs'])\n",
    "    prev_loss = 0\n",
    "    while delta_loss > 1e-6 and epoch < n_epochs:\n",
    "\n",
    "        # Training\n",
    "        clf = LogisticRegression()\n",
    "        X_train, y_train = np.zeros((0, n_out * 2)), []\n",
    "        X_test, y_test = np.zeros((0, n_out * 2)), []\n",
    "\n",
    "        train_err = 0\n",
    "        train_batches = 0\n",
    "        start_time = time.time()\n",
    "        if b_load_idxs_only:\n",
    "            for X, y in generate_new_dataset_batch_from_idxs(\n",
    "                data['X'],\n",
    "                data['y'],\n",
    "                data['X_train_matched_idxs'],\n",
    "                data['y_train_matched_idxs'],\n",
    "                data['X_train_unmatched_idxs'],\n",
    "                data['y_train_unmatched_idxs'],\n",
    "                batch_size\n",
    "            ):\n",
    "                err, y_pred = train_model(X, y)\n",
    "                X_train = np.r_[\n",
    "                    (X_train, np.reshape(y_pred, (batch_size / 2, n_out * 2)))]\n",
    "                y_train = np.r_[(y_train, y[::2])]\n",
    "                train_batches += 1\n",
    "                train_err += err\n",
    "        else:\n",
    "            for X, y in generate_new_dataset_batch(\n",
    "                data['X_train_matched'],\n",
    "                data['y_train_matched'],\n",
    "                data['X_train_unmatched'],\n",
    "                data['y_train_unmatched'],\n",
    "                batch_size\n",
    "            ):\n",
    "                err, y_pred = train_model(X, y)\n",
    "                X_train = np.r_[\n",
    "                    (X_train, np.reshape(y_pred, (batch_size / 2, n_out * 2)))]\n",
    "                y_train = np.r_[(y_train, y[::2])]\n",
    "                train_batches += 1\n",
    "                train_err += err\n",
    "        # Validation\n",
    "        val_err = 0\n",
    "        val_acc = 0\n",
    "        val_batches = 0\n",
    "\n",
    "        if b_load_idxs_only:\n",
    "            for X, y in generate_new_dataset_batch_from_idxs(\n",
    "                data['X'],\n",
    "                data['y'],\n",
    "                data['X_valid_matched_idxs'],\n",
    "                data['y_valid_matched_idxs'],\n",
    "                data['X_valid_unmatched_idxs'],\n",
    "                data['y_valid_unmatched_idxs'],\n",
    "                batch_size\n",
    "            ):\n",
    "                err, acc, y_pred = validate_model(X, y)\n",
    "                X_test = np.r_[\n",
    "                    (X_test, np.reshape(y_pred, (batch_size / 2, n_out * 2)))]\n",
    "                y_test = np.r_[(y_test, y[::2])]\n",
    "                val_err += err\n",
    "                val_acc += acc\n",
    "                val_batches += 1\n",
    "        else:\n",
    "            for X, y in generate_new_dataset_batch(\n",
    "                data['X_valid_matched'],\n",
    "                data['y_valid_matched'],\n",
    "                data['X_valid_unmatched'],\n",
    "                data['y_valid_unmatched'],\n",
    "                batch_size\n",
    "            ):\n",
    "                err, acc, y_pred = validate_model(X, y)\n",
    "                X_test = np.r_[\n",
    "                    (X_test, np.reshape(y_pred, (batch_size / 2, n_out * 2)))]\n",
    "                y_test = np.r_[(y_test, y[::2])]\n",
    "                val_err += err\n",
    "                val_acc += acc\n",
    "                val_batches += 1\n",
    "\n",
    "        # Measure Performance\n",
    "        X_train_L1 = np.abs(X_train[:, :n_out] - X_train[:, n_out:])\n",
    "        X_test_L1 = np.abs(X_test[:, :n_out] - X_test[:, n_out:])\n",
    "        clf.fit(X_train_L1, y_train)\n",
    "        y_true, y_pred = y_test, clf.predict(X_test_L1)\n",
    "        auc = metrics.roc_auc_score(y_true, y_pred)\n",
    "        f1 = metrics.f1_score(y_true, y_pred)\n",
    "\n",
    "        # Report\n",
    "        print(\"Epoch {} of {} took {:.3f}s\".format(\n",
    "            epoch + 1, n_epochs, time.time() - start_time))\n",
    "        print(\"\\ttraining loss:\\t\\t\\t{:.6f}\".format(train_err / train_batches))\n",
    "        print(\"\\tvalidation loss:\\t\\t{:.6f}\".format(val_err / val_batches))\n",
    "        print(\"\\tvalidation AUC:\\t\\t\\t{:.2f}\".format(auc))\n",
    "        print(\"\\tvalidation F1:\\t\\t\\t{:.2f}\".format(f1))\n",
    "\n",
    "        if (prev_loss - train_err / train_batches) < 0:\n",
    "            model.set_learning_rate(model.get_learning_rate() * 0.5)\n",
    "\n",
    "        delta_loss = np.abs(prev_loss - train_err / train_batches)\n",
    "        prev_loss = train_err / train_batches\n",
    "\n",
    "        results['epochs'].append(\n",
    "            {\n",
    "                'epoch': epoch,\n",
    "                'training_loss': train_err / train_batches,\n",
    "                'validation_loss': val_err / val_batches,\n",
    "                'accuracy': val_acc / val_batches * 100,\n",
    "                'f1': f1,\n",
    "                'auc': auc\n",
    "            }\n",
    "        )\n",
    "        # results['model'] = pickle.dumps(model)\n",
    "        results['model_parameters'] = pickle.dumps(model.retrieve_parameters())\n",
    "\n",
    "        pickle.dump(results, open(filename, 'wb'))\n",
    "        epoch = epoch + 1\n",
    "\n",
    "    # Now train a logistic regression classifer which will use the\n",
    "    # siamese network embedding of an image\n",
    "    # First generate stacked features from image pairs which will be used as\n",
    "    # input features\n",
    "    Xs, ys, imgs = np.zeros(\n",
    "        (0, n_out * 2)), [], np.zeros((0, 1, data['X'].shape[2], data['X'].shape[3]))\n",
    "    if b_load_idxs_only:\n",
    "        for split in ['train', 'valid', 'test']:\n",
    "            for X, y in generate_new_dataset_batch_from_idxs(\n",
    "                data['X'],\n",
    "                data['y'],\n",
    "                data['X_' + split + '_matched_idxs'],\n",
    "                data['y_' + split + '_matched_idxs'],\n",
    "                data['X_' + split + '_unmatched_idxs'],\n",
    "                data['y_' + split + '_unmatched_idxs'],\n",
    "                batch_size\n",
    "            ):\n",
    "                err, acc, pred = test_model(X, y)\n",
    "                Xs = np.r_[(Xs, np.reshape(pred, (batch_size / 2, n_out * 2)))]\n",
    "                ys = np.r_[(ys, y[::2])]\n",
    "                # imgs = np.r_[(X, imgs)]\n",
    "    else:\n",
    "        for split in ['train', 'valid', 'test']:\n",
    "            for X, y in generate_new_dataset_batch(\n",
    "                data['X_' + split + '_matched'],\n",
    "                data['y_' + split + '_matched'],\n",
    "                data['X_' + split + '_unmatched'],\n",
    "                data['y_' + split + '_unmatched'],\n",
    "                batch_size\n",
    "            ):\n",
    "                err, acc, pred = test_model(X, y)\n",
    "                Xs = np.r_[(Xs, np.reshape(pred, (batch_size / 2, n_out * 2)))]\n",
    "                ys = np.r_[(ys, y[::2])]\n",
    "                # imgs = np.r_[(X, imgs)]\n",
    "\n",
    "    results['prediction']['X'] = Xs\n",
    "    results['prediction']['y'] = ys\n",
    "    # results['prediction']['imgs'] = imgs\n",
    "\n",
    "    Xs_L1 = np.abs(Xs[:, :n_out] - Xs[:, n_out:])\n",
    "\n",
    "    skf = cross_validation.StratifiedKFold(ys, n_folds=4, random_state=0)\n",
    "    for train_index, test_index in skf:\n",
    "        X_train, y_train = Xs_L1[train_index], ys[train_index]\n",
    "        X_test, y_test = Xs_L1[test_index], ys[test_index]\n",
    "\n",
    "        # if False:\n",
    "        #     scaler = StandardScaler()\n",
    "        #     scaler.fit(X_train)\n",
    "        #     X_train = scaler.transform(X_train)\n",
    "        #     X_test = scaler.transform(X_test)\n",
    "\n",
    "        clf = LogisticRegression()\n",
    "        clf.fit(X_train, y_train)\n",
    "        y_true, y_pred = y_test, clf.predict(X_test)\n",
    "        # collect a few metrics:\n",
    "        results['prediction']['auc'].append(\n",
    "            metrics.roc_auc_score(y_true, y_pred))\n",
    "        results['prediction']['F1'].append(metrics.f1_score(y_true, y_pred))\n",
    "        results['prediction']['log_loss'].append(\n",
    "            metrics.log_loss(y_true, y_pred))\n",
    "\n",
    "        # store the resulting model\n",
    "        results['prediction']['W'].append(clf.coef_)\n",
    "\n",
    "    print('AUC: ', np.mean(results['prediction']['auc']))\n",
    "    print('F1: ', np.mean(results['prediction']['F1']))\n",
    "    results['model'] = pickle.dumps(model)\n",
    "    results['model_parameters'] = pickle.dumps(model.retrieve_parameters())\n",
    "\n",
    "    pickle.dump(results, open(filename, 'wb'))\n",
    "\n",
    "\n",
    "def main(argv):\n",
    "    \n",
    "    from argparse import ArgumentParser, ArgumentDefaultsHelpFormatter\n",
    "\n",
    "    parser = ArgumentParser(formatter_class=ArgumentDefaultsHelpFormatter)\n",
    "    # parser.add_argument('-h', '--help', help='Display help.', action=printUsage())\n",
    "    parser.add_argument('-m', '--model_type',\n",
    "                        help='Choose the Deep Network to use. [\"hani\"], \"chopra\", or \"custom\"',\n",
    "                        default='hani', dest='model_type')\n",
    "    parser.add_argument('-of', '--output_features',\n",
    "                        help='Number of features in the final siamese network layer',\n",
    "                        default=40, dest='n_out')\n",
    "    parser.add_argument('-bs', '--batch_size',\n",
    "                        help='Number of observations per batch.',\n",
    "                        default=100, dest='batch_size')\n",
    "    parser.add_argument('-e', '--epochs',\n",
    "                        help='Number of epochs to train for.',\n",
    "                        default=5, dest='n_epochs')\n",
    "    parser.add_argument('-lr', '--learning_rate',\n",
    "                        help='Initial learning rate to apply to the gradient update.',\n",
    "                        default=1e-4, dest='learning_rate')\n",
    "    parser.add_argument('-norm', '--normalization',\n",
    "                        help='Normalization of the dataset using either [\"-1:1\"], \"LCN\", \"LCN-\", or \"ZCA\".',\n",
    "                        default='-1:1', dest='normalization')\n",
    "    parser.add_argument('-f', '--filename',\n",
    "                        help='Resulting pickle file to store results. If none is given, a filename is created based on the combination of all parameters.',\n",
    "                        default=None, dest='filename')\n",
    "    parser.add_argument('-path', '--path_to_data',\n",
    "                        help='Path to the dataset.  If none is given it is assumed to be in the current working directory',\n",
    "                        default=None, dest='path_to_data')\n",
    "    parser.add_argument('-hm', '--hyperparameter_margin',\n",
    "                        help='Contrastive Loss parameter describing the total free energy.',\n",
    "                        default=2.0, dest='hyperparameter_margin')\n",
    "    parser.add_argument('-ht', '--hyperparameter_threshold',\n",
    "                        help='Threshold to apply to the difference in the final output layer.',\n",
    "                        default=5.0, dest='hyperparameter_threshold')\n",
    "    parser.add_argument('-ds', '--dataset',\n",
    "                        help='The dataset to train/test with. Choose from [\"lfw\"], or \"olivetti\"',\n",
    "                        default='lfw', dest='dataset')\n",
    "    parser.add_argument('-nl', '--nonlinearity',\n",
    "                        help='Non-linearity to apply to convolution layers.',\n",
    "                        default='rectify', dest='nonlinearity')\n",
    "    parser.add_argument('-fn', '--distance_fn',\n",
    "                        help='Distance function to apply to final siamese layer.',\n",
    "                        default='l2', dest='distance_fn')\n",
    "    parser.add_argument('-cf', '--cropfactor',\n",
    "                        help='Scale factor of amount of image around the face to use.',\n",
    "                        default=1.0, dest='crop_factor')\n",
    "    parser.add_argument('-sp', '--spatial_transform',\n",
    "                        help='Whether or not to prepend a spatial transform network',\n",
    "                        default=False, dest='spatial')\n",
    "    parser.add_argument('-r', '--resolution',\n",
    "                        help='Rescale images to this fixed square pixel resolution (e.g. 64 will mean images, after any crops, are rescaled to 64 x 64). ',\n",
    "                        default=64, dest='resolution')\n",
    "    parser.add_argument('-nf', '--num_files',\n",
    "                        help='Number of files to load for each person.',\n",
    "                        default=2, dest='num_files')\n",
    "    parser.add_argument('-gray', '--grayscale',\n",
    "                        help='Convert images to grayscale.',\n",
    "                        default=True, dest='b_convert_to_grayscale')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    print(args)\n",
    "\n",
    "    run_siamese_net_training(dataset=args.dataset,\n",
    "                             spatial=args.spatial,\n",
    "                             batch_size=int(args.batch_size),\n",
    "                             learning_rate=float(args.learning_rate),\n",
    "                             model_type=args.model_type,\n",
    "                             n_epochs=int(args.n_epochs),\n",
    "                             n_out=int(args.n_out),\n",
    "                             crop_factor=float(args.crop_factor),\n",
    "                             num_files=int(args.num_files),\n",
    "                             resolution=int(args.resolution),\n",
    "                             normalization=args.normalization,\n",
    "                             nonlinearity=args.nonlinearity,\n",
    "                             distance_fn=args.distance_fn,\n",
    "                             b_convert_to_grayscale=int(\n",
    "                                 args.b_convert_to_grayscale),\n",
    "                             hyperparameter_margin=float(\n",
    "                                 args.hyperparameter_margin),\n",
    "                             hyperparameter_threshold=float(\n",
    "                                 args.hyperparameter_threshold),\n",
    "                             path_to_data=args.path_to_data,\n",
    "                             filename=args.filename)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv[1:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
