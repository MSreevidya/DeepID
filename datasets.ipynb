{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "import os\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy import misc\n",
    "import cv2\n",
    "from bson.binary import Binary\n",
    "\n",
    "\n",
    "def scale_crop(x, y, w, h, img_w, img_h, crop_factor=1.0):\n",
    "    x = x + w // 2 - w // 2 * crop_factor\n",
    "    y = y + h // 2 - h // 2 * crop_factor\n",
    "    w = w * crop_factor\n",
    "    h = h * crop_factor\n",
    "\n",
    "    if (x + w) > img_w:\n",
    "        x -= ((x + w) - img_w)\n",
    "    if (y + h) > img_h:\n",
    "        y -= ((y + h) - img_h)\n",
    "\n",
    "    x = np.clip(x, 0, img_w - w)\n",
    "    y = np.clip(y, 0, img_h - h)\n",
    "\n",
    "    return x, y, w, h\n",
    "\n",
    "\n",
    "class Datasets(object):\n",
    "\n",
    "   \n",
    "    def __init__(self,\n",
    "                 path_to_data=None,\n",
    "                 n_min_files_per_person=5,\n",
    "                 n_files_per_person=2,\n",
    "                 b_convert_to_grayscale=False,\n",
    "                 crop_style='none',\n",
    "                 crop_factor=0.75,\n",
    "                 resolution=(64, 64),\n",
    "                 b_convert_img_to_serializable=False,\n",
    "                 b_augment_w_flips=False,\n",
    "                 b_augment_w_affine=True,\n",
    "                 area_threshold=1.0,\n",
    "                 similar_img_threshold=0.1):\n",
    "        self.path_to_data = path_to_data\n",
    "        self.n_min_files_per_person = n_min_files_per_person\n",
    "        if n_files_per_person is None:\n",
    "            self.n_files_per_person = 2\n",
    "        else:\n",
    "            self.n_files_per_person = n_files_per_person\n",
    "        self.b_convert_to_grayscale = b_convert_to_grayscale\n",
    "        self.crop_style = crop_style if crop_factor != 1.0 else 'none'\n",
    "        self.crop_factor = crop_factor\n",
    "        self.resolution = resolution\n",
    "        self.b_convert_img_to_serializable = b_convert_img_to_serializable\n",
    "        self.similar_img_threshold = similar_img_threshold\n",
    "        self.bCropToHOG = 'hog' in self.crop_style\n",
    "        self.bCropToHaar = 'haar' in self.crop_style\n",
    "        self.b_augment_w_flips = b_augment_w_flips\n",
    "        self.b_augment_w_affine = b_augment_w_affine\n",
    "        self.n_warps = self.n_files_per_person\n",
    "        self.area_threshold = area_threshold\n",
    "\n",
    "        if crop_style == 'haar':\n",
    "            self.face_cascade = cv2.CascadeClassifier(\n",
    "                'haarcascade_frontalface_default.xml')\n",
    "        elif crop_style == 'hog':\n",
    "            import dlib\n",
    "            self.detector = dlib.get_frontal_face_detector()\n",
    "        elif 'clm' in crop_style:\n",
    "            import menpo_clm as mp\n",
    "            self.clm = mp.CLM()\n",
    "        elif 'trees' in crop_style:\n",
    "            import faces as f\n",
    "            self.model = f.FaceShapeModel()\n",
    "        elif crop_style == 'none':\n",
    "            pass\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                'Unknown crop style.  Known options: [\"trees\"], \"hog+clm\", \"haar+clm\", \"hog\", and \"haar\"')\n",
    "\n",
    "    def get_parsed_dataset(self, dataset='lfw', path_to_data=None):\n",
    "        filename = None\n",
    "\n",
    "        filename = 'ds-{ds}_files-{n_files_per_person}_crop_style-{crop_style}_flips-{b_augment_w_flips}_warps-{b_augment_w_affine}_crop_factor-{crop_factor}_resolution-{x}x{y}_grayscale-{grayscale}.pkl'.format(\n",
    "            ds=dataset,\n",
    "            n_files_per_person=self.n_files_per_person,\n",
    "            crop_style=self.crop_style,\n",
    "            crop_factor=self.crop_factor,\n",
    "            x=self.resolution[0],\n",
    "            y=self.resolution[1],\n",
    "            grayscale=self.b_convert_to_grayscale,\n",
    "            b_augment_w_affine=self.b_augment_w_affine,\n",
    "            b_augment_w_flips=self.b_augment_w_flips)\n",
    "\n",
    "        # Check if we already have processed this dataset into a pickle file\n",
    "        ds = None\n",
    "        if os.path.exists(filename):\n",
    "            try:\n",
    "                with open(filename, 'rb') as f:\n",
    "                    ds = pickle.load(f)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        if ds is None:\n",
    "            print('Preprocessing dataset')\n",
    "            # nope, load it\n",
    "            if dataset == 'lfw':\n",
    "                ds = self._get_lfw_dataset(path_to_data=path_to_data)\n",
    "            else:\n",
    "                ds = self._get_kad_dataset(path_to_data=path_to_data)\n",
    "\n",
    "            # keep it cached as a pickle file so we don't have to load it again\n",
    "            try:\n",
    "                with open(filename, 'wb') as f:\n",
    "                    pickle.dump(ds, f, pickle.HIGHEST_PROTOCOL)\n",
    "            except:\n",
    "                os.remove(filename)\n",
    "                print('Could not pickle!')\n",
    "\n",
    "        # Check that we have the right number of images per person\n",
    "        labels = [d['y'] for d in ds]\n",
    "        good_idxs = None\n",
    "        n_bins = len(np.unique(labels))\n",
    "        if self.n_files_per_person is None:\n",
    "            good_idxs = range(n_bins)\n",
    "        else:\n",
    "            hist, edges = np.histogram(labels, bins=n_bins)\n",
    "            good_idxs = np.where(hist >= self.n_files_per_person)[0]\n",
    "\n",
    "        # Randomly permute the images and select the right number of images\n",
    "        images = []\n",
    "        labels = []\n",
    "        for idx in good_idxs:\n",
    "            this_imgs = np.concatenate([d['X'] for d in ds if idx == d['y']])\n",
    "            this_lbls = np.array([d['y'] for d in ds if idx == d['y']])\n",
    "            indices = None\n",
    "            if self.n_files_per_person is None:\n",
    "                indices = np.random.permutation(len(this_lbls))\n",
    "            else:\n",
    "                indices = np.random.permutation(\n",
    "                    len(this_lbls))[:np.min((\n",
    "                        self.n_files_per_person,\n",
    "                        len(this_lbls)\n",
    "                    ))]\n",
    "            images.append(this_imgs[indices, ...])\n",
    "            labels.append(this_lbls[indices, ...])\n",
    "\n",
    "        # Return dict in same format as olivetti dataset\n",
    "        return {'images': np.concatenate(images), 'target': np.hstack(labels)}\n",
    "\n",
    "    def _get_lfw_dataset(self, path_to_data=None):\n",
    "        import os\n",
    "        if self.path_to_data is None:\n",
    "            path_to_data = os.path.join(os.getcwd(), 'lfw')\n",
    "        if os.path.exists(path_to_data):\n",
    "            return self._get_one_level_deep(\n",
    "                path_to_data=path_to_data, token1='', token2='.jpg'\n",
    "            )\n",
    "        else:\n",
    "            print('Cannot find dataset at: %s' % (path_to_data))\n",
    "            print(\n",
    "                'Downloading dataset from http://vis-www.cs.umass.edu/lfw/lfw.tgz...')\n",
    "            os.system('wget http://vis-www.cs.umass.edu/lfw/lfw.tgz')\n",
    "            print('Extracting dataset...')\n",
    "            os.system('tar -xvf lfw.tgz')\n",
    "            return self._get_one_level_deep(\n",
    "                path_to_data='./lfw', token1='', token2='.jpg'\n",
    "            )\n",
    "\n",
    "    def _get_kad_dataset(self, path_to_data=None):\n",
    "        import os\n",
    "        if self.path_to_data is None:\n",
    "            path_to_data = os.path.join(os.getcwd(), 'kadenze_faces')\n",
    "        return self._get_two_level_deep(\n",
    "            path_to_data=path_to_data, token1='captured', token2='.jpg'\n",
    "        )\n",
    "\n",
    "    def _augment_img(self, img):\n",
    "        ds = []\n",
    "        ds.append(img)\n",
    "\n",
    "        if self.b_convert_to_grayscale:\n",
    "            orig_img = np.squeeze(img['X'])\n",
    "        else:\n",
    "            orig_img = np.rollaxis(np.squeeze(img['X']), 0, 3)\n",
    "\n",
    "        img_flipped = img.copy()\n",
    "\n",
    "        if self.b_augment_w_flips:\n",
    "\n",
    "            if self.b_convert_to_grayscale:\n",
    "                x_aug = cv2.flip(orig_img, flipCode=1)\n",
    "                img_flipped['X'] = x_aug[np.newaxis, ...]\n",
    "            else:\n",
    "                x_aug = np.concatenate((\n",
    "                    cv2.flip(orig_img[:, :, 0], flipCode=1)[..., np.newaxis],\n",
    "                    cv2.flip(orig_img[:, :, 1], flipCode=1)[..., np.newaxis],\n",
    "                    cv2.flip(orig_img[:, :, 2], flipCode=1)[..., np.newaxis]\n",
    "                ), axis=2)\n",
    "                img_flipped['X'] = np.rollaxis(x_aug, -1)[np.newaxis, ...]\n",
    "\n",
    "            ds.append(img_flipped)\n",
    "\n",
    "        if self.b_augment_w_affine:\n",
    "\n",
    "            for i in range(self.n_warps):\n",
    "\n",
    "                img_warped = img.copy()\n",
    "\n",
    "                # rotate w/ N(0, 2.0) degrees and scale w/ N(1.0, 0.067)\n",
    "                # percent of the image\n",
    "                M = cv2.getRotationMatrix2D(\n",
    "                    (img['X'].shape[2] / 2.0, img['X'].shape[1] / 2.0),\n",
    "                    angle=np.random.normal(0.0, 2.0),\n",
    "                    scale=np.random.normal(1.0, 0.067)\n",
    "                )\n",
    "                img_warped['X'] = cv2.warpAffine(\n",
    "                    orig_img,\n",
    "                    M,\n",
    "                    dsize=(orig_img.shape[1], orig_img.shape[0]),\n",
    "                    borderMode=cv2.BORDER_WRAP\n",
    "                )\n",
    "\n",
    "                # translate w/ N(1.0, 0.067) percent of the image\n",
    "                M = np.array([[np.random.normal(1.0, 0.067), 0.0, 0.0], [\n",
    "                             0.0, np.random.normal(1.0, 0.067), 0.0]])\n",
    "                img_warped['X'] = cv2.warpAffine(\n",
    "                    img_warped['X'],\n",
    "                    M, dsize=(orig_img.shape[1], orig_img.shape[0]),\n",
    "                    borderMode=cv2.BORDER_WRAP\n",
    "                )\n",
    "\n",
    "                if self.b_convert_to_grayscale:\n",
    "                    img_warped['X'] = img_warped['X'][np.newaxis, ...]\n",
    "                else:\n",
    "                    img_warped['X'] = np.rollaxis(\n",
    "                        img_warped['X'], -1)[np.newaxis, ...]\n",
    "\n",
    "                ds.append(img_warped)\n",
    "        return ds\n",
    "\n",
    "    def _get_one_level_deep(self, path_to_data, token1='', token2='.jpg'):\n",
    "   \n",
    "        print('Loading data in %s' % path_to_data)\n",
    "        ds = []\n",
    "        dirs = [direc for direc in os.listdir(path_to_data) if os.path.isdir(\n",
    "            os.path.join(path_to_data, direc))]\n",
    "        # Randomize directories\n",
    "        indices = np.random.permutation(len(dirs))\n",
    "        for label_i, direc in enumerate([dirs[dir_i] for dir_i in indices]):\n",
    "            print('Person: {current}/{total}'.format(\n",
    "                current=label_i, total=len(dirs)), end='\\r')\n",
    "            files = os.listdir(os.path.join(path_to_data, direc))\n",
    "            good_files = [\n",
    "                file_i for file_i in files\n",
    "                if token1 in file_i and\n",
    "                token2 in file_i\n",
    "            ]\n",
    "            for file_i, filename in enumerate(good_files):\n",
    "                img = self._preprocess_img(\n",
    "                    file_i=filename,\n",
    "                    label_i=label_i,\n",
    "                    pathToFile=os.path.join(path_to_data, direc),\n",
    "                    ds=ds\n",
    "                )\n",
    "                if img is not None:\n",
    "                    for img_augmented in self._augment_img(img):\n",
    "                        ds.append(img_augmented)\n",
    "        return ds\n",
    "\n",
    "    def _get_two_level_deep(self, path_to_data=None, token1='', token2='.jpg'):\n",
    "        import os\n",
    "        if path_to_data is None:\n",
    "            path_to_data = os.path.join(os.getcwd(), 'kadenze_faces')\n",
    "        print('Loading data in %s' % path_to_data)\n",
    "        ds = []\n",
    "        dirs = [direc for direc in os.listdir(path_to_data) if os.path.isdir(\n",
    "            os.path.join(path_to_data, direc))]\n",
    "        for label_i, direc in enumerate(dirs):\n",
    "            print(\n",
    "                'Person: {current}/{total}'.format(\n",
    "                    current=label_i, total=len(dirs)\n",
    "                ),\n",
    "                end='\\r'\n",
    "            )\n",
    "            sub_direcs = [\n",
    "                subdirec\n",
    "                for subdirec in os.listdir(\n",
    "                    os.path.join(path_to_data, direc)\n",
    "                )\n",
    "                if os.path.isdir(\n",
    "                    os.path.join(\n",
    "                        os.path.join(path_to_data, direc), subdirec)\n",
    "                )\n",
    "            ]\n",
    "            for pair in sub_direcs:\n",
    "                files = os.listdir(\n",
    "                    os.path.join(os.path.join(path_to_data, direc), pair))\n",
    "                good_files = [\n",
    "                    file_i for file_i in files\n",
    "                    if token1 in file_i and token2 in file_i\n",
    "                ]\n",
    "                if self.n_min_files_per_person is None:\n",
    "                    this_n_files = len(good_files)\n",
    "                else:\n",
    "                    this_n_files = np.min(\n",
    "                        (len(good_files), self.n_min_files_per_person))\n",
    "                if len(good_files) >= this_n_files:\n",
    "                    for file_i, filename in enumerate(good_files):\n",
    "                        img = self._preprocess_img(\n",
    "                            file_i=filename,\n",
    "                            label_i=label_i,\n",
    "                            pathToFile=os.path.join(\n",
    "                                os.path.join(path_to_data, direc), pair),\n",
    "                            ds=ds\n",
    "                        )\n",
    "                        if img is not None:\n",
    "                            for img_augmented in self._augment_img(img):\n",
    "                                ds.append(img_augmented)\n",
    "        return ds\n",
    "\n",
    "    def _preprocess_img(self,\n",
    "                        file_i,\n",
    "                        label_i,\n",
    "                        pathToFile,\n",
    "                        ds=None\n",
    "                        ):\n",
    "        # First process the crop\n",
    "        img = misc.imread(os.path.join(pathToFile, file_i)).astype(np.uint8)\n",
    "\n",
    "        gray_img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        x, y, w, h = None, None, None, None\n",
    "\n",
    "        if self.crop_style == 'haar':\n",
    "            faces = self.face_cascade.detectMultiScale(gray_img, 1.2)\n",
    "            if len(faces):\n",
    "                face = faces[0]\n",
    "                x, y, w, h = face[0], face[1], face[2], face[3]\n",
    "        elif self.crop_style == 'hog':\n",
    "            faces = self.detector(gray_img)\n",
    "            if len(faces):\n",
    "                face = faces[0]\n",
    "                x, y, w, h = face.left(), face.top(), face.right() - \\\n",
    "                    face.left(), face.bottom() - face.top()\n",
    "        elif 'clm' in self.crop_style:\n",
    "            fr = self.clm.fit(\n",
    "                gray_img,\n",
    "                bCropToHOG=self.bCropToHOG,\n",
    "                bCropToHaar=self.bCropToHaar\n",
    "            )\n",
    "            if fr is not None:\n",
    "                x, y, w, h = fr['bbox']\n",
    "        elif 'trees' in self.crop_style:\n",
    "            result = self.model.fit(gray_img)\n",
    "            if result is not None:\n",
    "                s = np.max(\n",
    "                    (result['face-bbox'][2:], result['pts-bbox'][2:])) / 2\n",
    "                x = result['nose'][0] - s\n",
    "                y = result['nose'][1] - s\n",
    "                w = s * 2\n",
    "                h = s * 2\n",
    "        elif self.crop_style == 'none':\n",
    "            x, y, w, h = [0, 0, img.shape[1], img.shape[0]]\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                'Unknown crop style.  Known options: [\"trees\"], \"hog+clm\", \"haar+clm\", \"hog\", and \"haar\"')\n",
    "\n",
    "        # test whether the detected image is above the area threshold\n",
    "        if (w * h) / (img.shape[0] * img.shape[1]) > self.area_threshold:\n",
    "            return None\n",
    "        # Scale the crop and apply it to the grayscale image\n",
    "        x, y, w, h = scale_crop(\n",
    "            x, y, w, h,\n",
    "            gray_img.shape[1], gray_img.shape[0],\n",
    "            self.crop_factor)\n",
    "        if self.b_convert_to_grayscale:\n",
    "            crop = gray_img[y:y + h, x:x + w]\n",
    "            img = misc.imresize(crop, self.resolution)[np.newaxis, ...]\n",
    "        else:\n",
    "            crop = img[y:y + h, x:x + w, ...]\n",
    "            img = np.rollaxis(\n",
    "                misc.imresize(crop, self.resolution),\n",
    "                -1)[np.newaxis, ...]\n",
    "        if np.max(img) > 0:\n",
    "            if ds is not None and self.similar_img_threshold > 0:\n",
    "                # check all other images with the same label\n",
    "                other_imgs = [d['X'] for d in ds if d['y'] == label_i]\n",
    "                for other_img in other_imgs:\n",
    "                    # calculate the l1 distance to that image\n",
    "                    l1dist = np.sum(\n",
    "                        np.abs(img.astype(float) / 255.0 -\n",
    "                               other_img.astype(float) / 255.0)\n",
    "                    ) / (img.shape[0] * img.shape[1] * img.shape[2])\n",
    "                    # if less than 5% of the pixels are different, it's\n",
    "                    # probably the same image\n",
    "                    if l1dist < self.similar_img_threshold:\n",
    "                        return None\n",
    "            if self.b_convert_img_to_serializable:\n",
    "                return {\n",
    "                    'filename': file_i,\n",
    "                    'y': label_i,\n",
    "                    'str_y': pathToFile,\n",
    "                    'shape': img.shape,\n",
    "                    'X': Binary(pickle.dumps(img, protocol=2), subtype=128)\n",
    "                }\n",
    "            else:\n",
    "                return {\n",
    "                    'filename': file_i,\n",
    "                    'y': label_i,\n",
    "                    'str_y': pathToFile,\n",
    "                    'shape': img.shape,\n",
    "                    'X': img\n",
    "                }\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
